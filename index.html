<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Rui Wang</title>
  <meta name="author" content="Rui Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/logo.png">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rui Wang (王锐)</name>
              </p>
              <p>I am a Senior Research Scientist at the <a href="https://www.microsoft.com/en-us/research/lab/mixed-reality-ai-zurich/">Microsoft Mixed Reality & AI Lab in Zurich</a>. Before joining Microsoft, I pursued my PhD in Computer Science in the <a href="https://vision.in.tum.de/">Chair of Computer Vision & Artificial Intelligence</a> at <a href="https://www.tum.de/en/">TUM</a>, where I was advised by <a href="https://vision.in.tum.de/members/cremers">Daniel Cremers</a>. In 2018, I did an internship in the <a href="https://blogs.nvidia.com/blog/2019/01/11/nvidia-seattle-ai-robotics-research-lab/">Nvidia Robotics Research Lab in Seattle</a>, supervised by <a href="https://homes.cs.washington.edu/~fox/">Dieter Fox</a>. In parallel with doing my PhD, I also worked as a Senior Computer Vision Researcher at <a href="https://www.artisense.ai/">Artisense</a>, a startup co-founded by Daniel. I received my Master from TUM and my Bachelor from <a href="http://en.xjtu.edu.cn/">Xi'an Jiaotong University</a>. 
              </p>
              <p>
                My research interests include visual odometry, SLAM, visual 3D reconstruction, as well as their combinations with semantic information. More broadly, I am interested in computer vision and machine learning.
              </p>
	      <p>
		If you are interested in these topics, feel free to reach out for internship and thesis opportunities.
	      </p>

              <p style="text-align:center">
                <a href="mailto:wangr@microsoft.com">Email</a> &nbsp/&nbsp
                <!-- <a href="data/XXX.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/XXX.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.de/citations?user=buN3yw8AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://www.researchgate.net/profile/Rui-Wang-268">ResearchGate</a>&nbsp/&nbsp -->
                <a href="https://www.linkedin.com/in/rui-wang-5367398a/">LinkedIn</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/XXX">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/rui2016">GitHub</a> &nbsp/&nbsp
                <a href="https://vision.in.tum.de/members/wangr">Homepage@TUM</a>
              </p>
            </td>
            <td style="padding:2.7%;width:36%;max-width:36%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/RuiWang_circle.png">
            </td>
          </tr>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
            </td>
          </tr>
        </tbody></table> 
        <table style="width:100%;padding-left:20px;padding-right:20px;padding-bottom:20px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px;width:10%;vertical-align:top">
              [03/2021]
            </td>
            <td>
              I join the <a href="https://www.microsoft.com/en-us/research/lab/mixed-reality-ai-zurich/">Microsoft Mixed Reality & AI Lab Zurich</a> as a Senior Research Scientist. 
            </td>
          </tr>
          <tr>
            <td style="padding:0px;width:10%;vertical-align:top">
              [05/2020]
            </td>
            <td>
              We are organizing a workshop with a challenge on <a href="https://sites.google.com/view/mlad-eccv2020">Map-based Localization for Autonomous Driving</a> at ECCV 2020.
            </td>
          </tr>
          </tr>
            <td style="padding:0px;width:10%;vertical-align:top">
              [05/2018]
            </td>
            <td>
              I will be interning with <a href="https://homes.cs.washington.edu/~fox/">Dieter Fox</a> in the Nvidia Robotics Research Lab in Seattle.
            </td >
          </tr>
          <tr>
            <td style="padding:0px;width:10%;vertical-align:top">
              [03/2018]
            </td>
            <td>
              I join <a href="https://www.artisense.ai/">Artisense</a> as a Senior Computer Vision Researcher and continue my PhD there.
            </td>
          </tr>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>  
        <table width="100%" align="center" border="0"><tbody>
          <tr>
            <td style="padding-left:20px;padding-right:20px;padding-top:10px;padding-bottom:10px;width:25%;vertical-align:middle">
              <img src="images/tum.png" alt="blind-date" width="140">
            </td>
            <td width="75%" valign="middle">
              <strong>Technical University of Munich</strong>
              <br>
              PhD
              <br>
              Computer Science
              <br>
              2016-2020
            </td>
          </tr>
          <tr>
            <td style="padding-left:20px;padding-right:20px;padding-top:10px;padding-bottom:10px;width:25%;vertical-align:middle">
              <img src="images/tum.png" alt="blind-date" width="140">
            </td>
            <td width="75%" valign="middle">
              <strong>Technical University of Munich</strong>
              <br>
              Master
              <br>
              Electrical Engineering and Information Technology
              <br>
              2011-2014
            </td>
          </tr>
          <tr>
            <td style="padding-left:20px;padding-right:20px;padding-top:10px;padding-bottom:10px;width:25%;vertical-align:middle">
              <img src="images/xjtu.jpg" alt="blind-date" width="140">
            </td>
            <td width="75%" valign="middle">
              <strong>Xi'an Jiaotong University</strong>
              <br>
              Bachelor
              <br>
              Automation
              <br>
              2007-2011
            </td>
          </tr>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Highlight Videos</heading>
            </td>
          </tr>
        </tbody></table>  
        <table width="100%" align="center" border="0"><tbody>
          <tr>
            <td style="padding-left:20px;padding-top:10px;width:50%;vertical-align:top">
              <iframe width="430" height="240" src="https://www.youtube.com/embed/QqP6zdx5OKw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </td>
            <td style="padding-right:20px;padding-top:10px;width:50%;vertical-align:top">
              <iframe width="430" height="240" src="https://www.youtube.com/embed/nQHMG0c6Iew" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </td>
          </tr>
          <tr>
            <td style="padding-left:20px;padding-bottom:20px;width:50%;vertical-align:top">
              <iframe width="430" height="240" src="https://www.youtube.com/embed/A53vJO8eygw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </td>
            <td style="padding-right:20px;padding-bottom:20px;width:50%;vertical-align:top">
              <iframe width="430" height="240" src="https://www.youtube.com/embed/sLZOeC9z_tw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            </td>
          </tr>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;padding-bottom:0px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/xia2021soe.png" alt="fast-texture" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://github.com/Yan-Xia/SOE-Net">
                <papertitle>SOE-Net: A Self-Attention and Orientation Encoding Network for Point Cloud based Place Recognition</papertitle>
              </a>
              <br>
              Yan Xia, Yusheng Xu, Shuang Li, <strong>Rui Wang</strong>, Juan Du, Daniel Cremers, Uwe Stilla
              <br>
              <em>CVPR</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="data/paper/xia2021soe.pdf">paper</a> | 
              <a href="https://github.com/Yan-Xia/SOE-Net">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/gladkova2021tight.png" alt="fast-texture" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://vision.in.tum.de/research/vslam/tirdso">
                <papertitle>Tight Integration of Feature-based Relocalization in Monocular Direct Visual Odometry</papertitle>
              </a>
              <br>
              Mariia Gladkova, <strong>Rui Wang</strong>, Niclas Zeller, Daniel Cremers
              <br>
              <em>ICRA</em>, 2021 
              <br>
              <a href="data/paper/gladkova2021tight.pdf">paper</a> | 
              <a href="https://vision.in.tum.de/research/vslam/tirdso">project page</a> |
              <a href="https://youtu.be/L2FHoxm9Oag">video</a> |
              <a href="https://youtu.be/b4p0Emwkpv4">teaser video</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/wenzel2020fourseasons.png" alt="fast-texture" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://www.4seasons-dataset.com/">
                <papertitle>4Seasons: A Cross-Season Dataset for Multi-Weather SLAM in Autonomous Driving</papertitle>
              </a>
              <br>
              Patrick Wenzel, <strong>Rui Wang</strong>, Nan Yang, Qing Cheng, Qadeer Khan,Lukas von Stumberg, Niclas Zeller, Daniel Cremers
              <br>
              <em>GCPR</em>, 2020
              <br>
              <a href="data/paper/wenzel2020fourseasons.pdf">paper</a> | 
              <a href="https://www.4seasons-dataset.com/">project page</a> |
              <a href="https://www.4seasons-dataset.com/dataset">dataset</a> |
              <a href="https://youtu.be/Vn84qyTGx7U">video</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/koestler2020learning.png" alt="fast-texture" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://lukaskoestler.com/ldwl">
                <papertitle>Learning Monocular 3D Vehicle Detection without 3D Bounding Box Labels</papertitle>
              </a>
              <br>
              Lukas Koestler, Nan Yang, <strong>Rui Wang</strong>, Daniel Cremers
              <br>
              <em>GCPR</em>, 2020
              <br>
              <a href="data/paper/koestler2020learning.pdf">paper</a> | 
              <a href="data/paper/koestler2020learning_supp.pdf">supplement</a> | 
              <a href="https://lukaskoestler.com/ldwl">project page</a> |
              <a href="https://lukaskoestler.com/static/ldwl_data_md5=4e59c6547b2ce0a8177be963ca75b864.zip">data</a> |
              <a href="https://youtu.be/1rxMDoIm6oM">video</a> |
              <a href="https://youtu.be/Qxj0-jASHUg">teaser video</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/du2020dh3d.png" alt="fast-texture" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://vision.in.tum.de/research/vslam/dh3d">
                <papertitle>DH3D: Deep Hierarchical 3D Descriptors for Robust Large-Scale 6DoF Relocalization</papertitle>
              </a>
              <br>
              Juan Du<sup>*</sup>, <strong>Rui Wang</strong><sup>*</sup>, Daniel Cremers
              <br>
              <em>ECCV</em>, 2020 &nbsp (<sup>*</sup>equal contribution) &nbsp <font color="red"><strong>(Spotlight Presentation)</strong></font>
              <br>
              <a href="data/paper/du2020dh3d.pdf">paper</a> | 
              <a href="data/paper/du2020dh3d_supp.pdf">supplement</a> | 
              <a href="https://vision.in.tum.de/research/vslam/dh3d">project page</a> |
              <a href="https://vision.in.tum.de/research/vslam/dh3d">data</a> |
              <a href="https://youtu.be/ZxZiwZugG14">video</a> |
              <a href="https://youtu.be/1oYtqJhHOLw">teaser video</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/yang20d3vo.png" alt="fast-texture" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://vision.in.tum.de/research/vslam/d3vo">
                <papertitle>D3VO: Deep Depth, Deep Pose and Deep Uncertainty for Monocular Visual Odometry</papertitle>
              </a>
              <br>
              Nan Yang, Lukas von Stumberg, <strong>Rui Wang</strong>, Daniel Cremers
              <br>
              <em>CVPR</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="data/paper/yang20d3vo.pdf">paper & supplement</a> | 
              <a href="https://vision.in.tum.de/research/vslam/d3vo">project page</a> |
              <a href="https://youtu.be/a7CAkJbhcm8">video</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/wang2020directshape.png" alt="fast-texture" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://vision.in.tum.de/research/vslam/direct-shape">
                <papertitle>DirectShape: Photometric Alignment of Shape Priors for Visual Vehicle Pose and Shape Estimation</papertitle>
              </a>
              <br>
              <strong>Rui Wang</strong>, Nan Yang, Joerg Stueckler, Daniel Cremers
              <br>
              <em>ICRA</em>, 2020
              <br>
              <a href="data/paper/wang2020directshape.pdf">paper</a> | 
              <a href="data/paper/wang2020directshape_supp.pdf">supplement</a> | 
              <a href="https://vision.in.tum.de/research/vslam/direct-shape">project page</a> |
              <a href="https://youtu.be/QqP6zdx5OKw">video</a> | 
              <a href="https://youtu.be/P_9fJa-PA9M">presentation</a> 
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/yang2018dvso.png" alt="fast-texture" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://vision.in.tum.de/research/vslam/dvso">
                <papertitle>Deep Virtual Stereo Odometry: Leveraging Deep Depth Prediction for Monocular Direct Sparse Odometry</papertitle>
              </a>
              <br>
              Nan Yang, <strong>Rui Wang</strong>, Joerg Stueckler, Daniel Cremers
              <br>
              <em>ECCV</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="data/paper/yang2018dvso.pdf">paper</a> | 
              <a href="data/paper/yang2018dvso_supp.pdf">supplement</a> | 
              <a href="https://vision.in.tum.de/research/vslam/dvso">project page</a> |
              <a href="https://youtu.be/sLZOeC9z_tw">video</a> | 
              <a href="https://youtu.be/2_nDLpGtY1Y">presentation</a> 
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/yang18challenges.png" alt="fast-texture" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://vision.in.tum.de/_media/spezial/bib/yang18challenges.pdf">
                <papertitle>Challenges in Monocular Visual Odometry: Photometric Calibration, Motion Bias and Rolling Shutter Effect</papertitle>
              </a>
              <br>
              Nan Yang<sup>*</sup>, <strong>Rui Wang</strong><sup>*</sup>, Xiang Gao, Daniel Cremers
              <br>
              <em>RA-L and IROS</em>, 2018 &nbsp (<sup>*</sup>equal contribution) 
              <br>
              <a href="data/paper/yang18challenges.pdf">paper</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/gao2018ldso.png" alt="fast-texture" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://vision.in.tum.de/research/vslam/ldso">
                <papertitle>LDSO: Direct Sparse Odometry with Loop Closure</papertitle>
              </a>
              <br>
              Xiang Gao, <strong>Rui Wang</strong>, Nikolaus Demmel, Daniel Cremers
              <br>
              <em>IROS</em>, 2018
              <br>
              <a href="data/paper/gao2018ldso.pdf">paper</a> |
              <a href="https://vision.in.tum.de/research/vslam/ldso">project page</a> |
              <a href="https://youtu.be/LEvOSzyZUvc">video</a> |
              <a href="https://github.com/tum-vision/LDSO">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/bergmann17calibration.png" alt="fast-texture" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://vision.in.tum.de/research/vslam/photometric-calibration">
                <papertitle>Online Photometric Calibration of Auto Exposure Video for Realtime Visual Odometry and SLAM</papertitle>
              </a>
              <br>
              Paul Bergmann, <strong>Rui Wang</strong>, Daniel Cremers
              <br>
              <em>RA-L and ICRA</em>, 2018 &nbsp <font color="red"><strong>(Best Vision Paper Award - Finalist)</strong></font>
              <br>
              <a href="data/paper/bergmann17calibration.pdf">paper</a> |
              <a href="https://vision.in.tum.de/research/vslam/photometric-calibration">project page</a> |
              <a href="https://youtu.be/nQHMG0c6Iew">video</a> |
              <a href="https://github.com/tum-vision/online_photometric_calibration">code</a>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/wang2017stereodso.png" alt="fast-texture" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://vision.in.tum.de/research/vslam/stereo-dso">
                <papertitle>Stereo DSO: Large-Scale Direct Sparse Visual Odometry with Stereo Cameras</papertitle>
              </a>
              <br>
              <strong>Rui Wang</strong><sup>*</sup>, Martin Schwoerer<sup>*</sup>, Daniel Cremers
              <br>
              <em>ICCV</em>, 2017 &nbsp (<sup>*</sup>equal contribution)
              <br>
              <a href="data/paper/wang2017stereodso.pdf">paper</a> |
              <a href="data/paper/wang2017stereodso_supp.pdf">supplement</a> |
              <a href="https://vision.in.tum.de/research/vslam/stereo-dso">project page</a> |
              <a href="https://youtu.be/A53vJO8eygw">video (VO)</a> |
              <a href="https://youtu.be/BxTLhubqEKg">video (SLAM)</a>
            </td>
          </tr>

        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Academic Services</heading>          
              <p>
                <strong>Conference reviewer</strong>
                <br>
                CVPR, ICCV, ECCV, ICRA, IROS, AAAI, NeurIPS, ICLR</dd>
              </p>
              <p>
                <strong>Journal reviewer</strong>
                <br>
                RA-L, T-RO, AURO, TMM, P&RS, Pattern Recognition, IJRR</dd>
              </p>
              <p>
                <strong>Organizer</strong>
                <br>
                ECCV 2020 Workshop on <a href="https://sites.google.com/view/mlad-eccv2020">Map-based Localization for Autonomous Driving</a>
              </p>
            </td>  
          </tr>
        </tbody></table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:40%;vertical-align:bottom">
              <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=lxMx_AjuLYtxWZPXB7oQ5SBakJQyAliP44INbNAsfpc&cl=ffffff&w=a"></script>
            </td>
            <td style="padding:20px;width:60%;vertical-align:bottom">
              <br>
              <p style="text-align:right;font-size:small;">
                Created based on <a href="https://jonbarron.info/">Jon Barron</a>'s <a href="https://github.com/jonbarron/jonbarron_website">code</a>.
              </p>
              <p style="text-align:right;font-size:small;">
                Last updated: August 23, 2022
              </p>
            </td>
          </tr>
        </tbody></table>


      </td>
    </tr>
  </table>
</body>

</html>
